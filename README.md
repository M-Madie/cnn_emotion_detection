# A Deep Learning Model that detects  Emotions in Human Voice

For my final project as a data science student I choose the topic of emotion recognition in human voice. I developed a Convolutional Neural Network architecture that classifies emotions from Spectograms produces from labeled audio recordings. I also developed a streamlit based web application that records live audio from the user, predicts the emotion and displays an emotion-specific response back to the user.

For the project the Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D) was used (https://www.kaggle.com/datasets/ejlok1/cremad)- a balanced dataset which include 7442 audio recordings, labeled with emotions belonging to six categories: fear, disgust, happiness, sadness, anger or neutral.

Emotions have been known to affect human speech resulting with differentiated patterns in the sound wave. An audio can be transformed into a Spectrogram image wich is a visual representation of the spectrum of frequencies of a signal as it varies with time. This enables for the use of deep learning models to classify emotions from voice recordings.

The repository includes the following files:
* 
